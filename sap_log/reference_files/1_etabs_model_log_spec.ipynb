{"nbformat":4,"nbformat_minor":5,"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"cells":[{"id":"743064fc","cell_type":"markdown","source":["# **1. Background and constraints**\n","\n","* Every time ETABS saves a model, it writes:\n","\n","  * A binary `.EDB` file (primary DB), and\n","  * A text backup `.$et` file with the same basename.\n","* `.$et` and `.e2k` are both *model text files* ETABS can import/export.\n","* The text files are organized in **sections** beginning with lines that start with `$` (e.g. `$ FRAME SECTIONS`, `$ LOAD COMBINATIONS`). Within each section, there are usually one-line records such as\n","  `FRAMESECTION \"W5X16\" MATERIAL \"A36\" SHAPE \"W5X16\"`\n","* CSI’s KB suggests that each text-field’s meaning is aligned with the “Print Tables” headers (exported as TXT/Excel).\n","\n","So the basic idea is “parse in chunks per `$ HEADER`, diff per chunk, then summarize”\n"],"metadata":{"id":"743064fc"}},{"id":"915f4587","cell_type":"markdown","source":["# **2. Concept details: what the system actually does**\n","\n","## 2.1. User-level behavior\n","\n","For a designer, the “automatic model log” should feel like:\n","\n","> “Every time I save (or commit) the ETABS model, a log entry appears saying things like:\n",">\n","> * *‘Story L14: 26 columns changed from W14x90 → W14x211 (Grids A–D / 1–4).’*\n","> * *‘New load combo 1.2D+1.0Wx+1.0L created.’*\n","> * *‘Concrete f’c for C30 changed from 4.0 ksi → 4.5 ksi.’*”\n","\n","No one ever sees raw `$et` diffs unless they go looking for them.\n","\n","## 2.2. Core pipeline\n","\n","For each new version of the model (two successive `.$et` files):\n","\n","1. **Raw text snapshot**\n","\n","   * Store/commit the `.$et` file (or `.e2k`, optional).\n","   * Optional git integration: each saved model version gets a commit or tag.\n","\n","2. **Text → structured model**\n","\n","   * Parse `.$et` into a structured in-memory object (or intermediate JSON) by:\n","\n","     * Splitting into `$`-header sections.\n","     * Parsing each section’s lines into typed records (e.g. `FrameSection`, `FrameAssign`, `Joint`, `GridLine`, `Story`, `LoadCombo`).\n","\n","3. **Semantic diff**\n","\n","   * Compare previous vs current structured models.\n","   * Produce a **typed change list**, e.g.:\n","\n","     * `FrameSectionChanged(name=\"W14X90\", field=\"Area\", old=XX, new=YY)`\n","     * `FrameAssignmentChanged(frame_id=2301, story=\"L14\", old_section=\"W14X90\", new_section=\"W14X211\")`\n","     * `LoadComboAdded(name=\"1.4D\")`, etc.\n","\n","4. **Domain-aware aggregation**\n","\n","   * Group low-level changes into patterns:\n","\n","     * By story, by grid, by section type, etc.\n","     * Example: detect that “all columns on Story L14 that *were* W14x90 are now W14x211” instead of a hundred separate frame changes.\n","\n","5. **LLM summarization & explanation**\n","\n","   * LLM takes the *aggregated* change data (small JSON, not the whole file) and produces:\n","\n","     * A concise summary for the log (“what changed?”).\n","     * Optionally, a richer explanation (“what does this mean structurally?”).\n","   * This is where statements like “column at grid A-1 changed from XXX to YYY” come from.\n","\n","6. **Outputs**\n","\n","   * **Machine-readable diff** (JSON) for tooling:\n","\n","     * For MCP tools, UI dashboards, further processing.\n","   * **Human-readable log** (Markdown/HTML/Plain-text):\n","\n","     * “ModelLog_2025-11-13.md” with sections like:\n","\n","       * Geometry changes\n","       * Section/Material changes\n","       * Load pattern/case/combo changes\n","       * Analysis/design settings changes\n"],"metadata":{"id":"915f4587"}},{"id":"548a1cbd","cell_type":"markdown","source":["# **3. Anticipated challenges & strategies**\n","\n","## 3.1. `$et` format quirks\n","\n","**Challenge:** `.$et` is a backup, not a formally documented API; the order of sections/records might change, some fields are volatile (timestamps, version numbers, etc.).\n","\n","**Strategies:**\n","\n","* Prefer **section-level parsing**:\n","\n","  * Use `$ HEADER` lines as natural boundaries.\n","* Within each section:\n","\n","  * Parse each line into a **dict of fields** (using quoted-string tokenization, known keywords).\n","  * For diffing, **sort** records by a stable key (e.g., object name, ID), so we’re not sensitive to ETABS reordering.\n","* Maintain a list of **volatile fields to ignore** in diffs (e.g., program version, date/time, “last analysis date”).\n","\n","## 3.2. Stable identity for objects\n","\n","**Challenge:** ETABS may renumber objects; textual IDs alone might not be stable (e.g., frame ID 2301 today could be 2310 tomorrow if we add/delete elements).\n","\n","**Strategies:**\n","\n","* Use **logical keys** wherever possible:\n","\n","  * Frame/column/beam: often have a “Label” or “Unique Name” that is more stable than an internal ID. When available, that becomes the key.\n","  * Use (Story, EndJointI, EndJointJ) triple as a fallback identity, where joint coordinates haven’t changed.\n","* Establish **matching heuristics**:\n","\n","  * For each “old” frame record, try:\n","\n","    1. Match by Label/Name.\n","    2. If missing, match by joint pair (within coordinate tolerance).\n","  * If no match, treat as removed/added element instead of a modified one.\n","\n","## 3.3. Numeric noise & insignificant changes\n","\n","**Challenge:** Small numeric differences (e.g., 12.0000 vs 12.0001) and internal defaults can create huge but meaningless diffs.\n","\n","**Strategies:**\n","\n","* Implement tolerance rules per field:\n","\n","  * Example: coordinate differences < 1e-4, stiffness modifiers differences < 1e-3 → ignored.\n","* Distinguish:\n","\n","  * **“Noisy” changes** (ignored or only show under “advanced details”).\n","  * **Material / geometric changes** (always reported).\n","\n","## 3.4. Large, pattern-like changes\n","\n","**Challenge:** Real-life operations (copying a story, changing a template, swapping all columns for a stronger size) can touch thousands of records.\n","\n","**Strategies:**\n","\n","* **Aggregate first, then summarise:**\n","\n","  * Group changes by (story, section_old, section_new, object_type).\n","  * Represent as “# of objects changed” rather than individual items.\n","* Detect high-level operations heuristically:\n","\n","  * Example: if 100% of beams on Story L14 appear as new, with same pattern as previous story L13 → summarise as “Story L15 added by copying L14 (N beams, M columns, etc.)”.\n","\n","## 3.5. Story & grid-based language (“column on grid A-1”)\n","\n","**Challenge:** `.$et` encodes coordinates, grid lines, and story elevations, but designers think in grids/stories.\n","\n","**Strategies:**\n","\n","* Parse these tables/sections:\n","\n","  * **Story data** (Story name, elevation).\n","  * **Grid lines** and their coordinates. ([CSI Knowledge Base][5])\n","  * **Joint coordinates** and connectivity.\n","* For each frame object:\n","\n","  * Lookup its end joints.\n","  * Map joint coordinates to nearest grid line in X and Y (within tolerance) → grid labels.\n","  * Map Z to story elevation → story name.\n","* Attach human-friendly tags:\n","\n","  * e.g. `location = {\"story\": \"L14\", \"grid_x\": \"A\", \"grid_y\": \"1\"}`.\n","* In LLM prompt, instruct: “When available, refer to frames as columns/beams at grid A-1 on Story L14.\"\n","\n","## 3.6. Performance and scaling\n","\n","**Challenge:** Big models → big text files (tens of MB). LLM context is limited and expensive.\n","\n","**Strategies:**\n","\n","* Keep LLM out of raw text:\n","\n","  * All raw parsing and diffing is deterministic code.\n","  * LLM only sees compact JSON summaries (aggregations, counts, a handful of representative examples).\n","* Use streaming / incremental diff:\n","\n","  * Only compute diff vs **previous version**, not vs entire history.\n","  * Optionally support “compare version X vs Y” with re-run of the same diff pipeline.\n"],"metadata":{"id":"548a1cbd"}},{"id":"045f550d","cell_type":"markdown","source":["# **4. Data model: what to parse and how**\n","\n","## 4.1. Focus for v1\n","\n","Start with sections that have direct design meaning:\n","\n","* `$ PROGRAM CONTROL` / meta (mostly ignored except version, analysis options).\n","* `$ MATERIAL PROPERTIES`\n","* `$ FRAME SECTIONS` (steel, concrete, etc.)\n","* `$ AREA SECTIONS` (slabs, walls).\n","* `$ POINT OBJECTS` / `$ JOINT COORDINATES`.\n","* `$ FRAME OBJECTS` / frame connectivity.\n","* `$ STORY DATA`.\n","* `$ GRID LINES`.\n","* `$ LOAD PATTERNS`, `$ LOAD CASES`, `$ LOAD COMBINATIONS`.\n","* `$ FRAME ASSIGNS` (sections, releases, modifiers, auto-mesh).\n","* (Optionally later) `$ AREA ASSIGNS`, diaphragm assignments, mass source, design preferences/overwrites.\n","\n","For each section, define:\n","\n","* **Record type** (e.g., `FrameSection`, `FrameAssignFrame`, `LoadCombo`).\n","* **Key fields** (for matching: name, label, ID).\n","* **Important attributes** vs **low-priority** ones.\n","\n","## 4.2. Internal representation\n","\n","Use a structured model, e.g. Python dataclasses or pydantic models:\n"],"metadata":{"id":"045f550d"}},{"id":"c9e601e9","cell_type":"code","metadata":{"id":"c9e601e9"},"execution_count":null,"source":["from dataclasses import dataclass\n","from typing import Optional\n","\n","@dataclass\n","class FrameSection:\n","    name: str\n","    material: str\n","    shape: str\n","    # Optional numeric properties (area, Ix, Iy, etc.) if present\n","\n","@dataclass\n","class FrameObject:\n","    name: str  # ETABS object label\n","    story: str\n","    joint_i: str\n","    joint_j: str\n","    section: str\n","    # computed later\n","    grid_x: Optional[str] = None\n","    grid_y: Optional[str] = None\n","\n","@dataclass\n","class LoadCombo:\n","    name: str\n","    design_type: Optional[str]\n","    terms: list  # list[LoadComboTerm]  # combination of patterns/cases with SFs\n"],"outputs":[]},{"id":"a98fb114","cell_type":"markdown","source":["…and so on.\n","\n","The **structured model** object then has collections:\n"],"metadata":{"id":"a98fb114"}},{"id":"32e3da1e","cell_type":"code","metadata":{"id":"32e3da1e"},"execution_count":null,"source":["from dataclasses import dataclass\n","from typing import Dict, List\n","\n","@dataclass\n","class EtabsModel:\n","    program_info: 'ProgramInfo'\n","    stories: Dict[str, 'Story']\n","    grids: List['GridLine']\n","    joints: Dict[str, 'Joint']\n","    frames: Dict[str, 'FrameObject']\n","    frame_sections: Dict[str, 'FrameSection']\n","    load_combos: Dict[str, 'LoadCombo']\n","    # etc.\n"],"outputs":[]},{"id":"9bef7583","cell_type":"markdown","source":["The structured model object then has collections as shown above.\n"],"metadata":{"id":"9bef7583"}},{"id":"31940f32","cell_type":"markdown","source":["# **5. Diff engine design**\n","\n","## 5.1. General pattern\n","\n","For each collection (by type):\n","\n","* Compute:\n","\n","  * **Added** keys: present in new, not in old.\n","  * **Removed** keys: present in old, not in new.\n","  * **Possibly modified** keys: present in both → field-by-field comparison with tolerances.\n","\n","Produce **typed change objects**, e.g.:\n"],"metadata":{"id":"31940f32"}},{"id":"d3ebbeb2","cell_type":"code","metadata":{"id":"d3ebbeb2"},"execution_count":null,"source":["from dataclasses import dataclass\n","from typing import Dict\n","\n","@dataclass\n","class FrameSectionChanged:\n","    name: str\n","    changed_fields: Dict[str, 'FieldChange']\n","\n","@dataclass\n","class FrameAssignmentChanged:\n","    frame_name: str\n","    story: str\n","    location: 'LocationInfo'\n","    old_section: str\n","    new_section: str\n"],"outputs":[]},{"id":"8309b2af","cell_type":"markdown","source":["## 5.2. Aggregation pass\n","\n","On top of the raw change list:\n","\n","* Cluster changes by patterns, e.g.:\n"],"metadata":{"id":"8309b2af"}},{"id":"1fbc0eed","cell_type":"code","metadata":{"id":"1fbc0eed"},"execution_count":null,"source":["from dataclasses import dataclass\n","from typing import Literal, Optional, List\n","\n","@dataclass\n","class SectionSwapCluster:\n","    object_type: Literal[\"column\", \"beam\", \"brace\", \"frame\"]\n","    story: Optional[str]  # e.g. \"L14\"\n","    grid_region: Optional['GridRegion']  # e.g. {\"grid_x\": [\"A\",\"B\"], \"grid_y\": [\"1\",\"2\"]}\n","    old_section: str\n","    new_section: str\n","    count: int\n","    example_objects: List[str]\n"],"outputs":[]},{"id":"c1212bcd","cell_type":"markdown","source":["* Similar clusters for:\n","\n","  * Added/removed frames by region.\n","  * Material property changes.\n","  * Load combination changes (new combos, changed factors, etc.).\n","\n","## 5.3. Change categories\n","\n","Tag each cluster by high-level **category**:\n","\n","* `\"geometry\"`: new/deleted frames, changes in joint coordinates, story heights.\n","* `\"member_properties\"`: section swaps, modifiers, material changes.\n","* `\"loads\"`: load patterns, cases, combos, assignments.\n","* `\"analysis_settings\"`: mass source, P-Δ, nonlinear options.\n","* `\"design_settings\"`: design codes, phi factors, overwrite changes.\n","\n","These tags feed directly into LLM prompts (“group summaries by category”).\n"],"metadata":{"id":"c1212bcd"}},{"id":"7bcccd36","cell_type":"markdown","source":["# **6. LLM + MCP integration**\n","\n","## 6.1. Role of the LLM\n","\n","LLM should **not** parse `$et` or raw diffs. Its jobs:\n","\n","1. **Semantic compression**:\n","\n","   * Input: JSON structure describing aggregated changes (clusters).\n","   * Output: succinct Markdown/HTML summary:\n","\n","     * Bullet points per category.\n","     * Use human-friendly terminology (“columns on Story L14”, “grid A-1”, “gravity load combo”, etc.).\n","\n","2. **Explanation** (optional mode):\n","\n","   * Given a change cluster, explain structural implications:\n","\n","     * “Increasing columns from W14x90 to W14x211 on L14 increases axial and flexural capacity; likely a response to higher demand or design criteria.”\n","\n","3. **Q&A over diffs** (via MCP tools):\n","\n","   * Tools to let the LLM answer follow-up queries:\n","\n","     * “Which stories had section changes?”\n","     * “Which load combos were modified between v12 and v13?”\n","\n","## 6.2. MCP server sketch\n","\n","Implement an MCP server exposing tools like:\n","\n","* `list_model_versions(model_path)`\n","  → returns known `$et` snapshots with timestamps and tags.\n","\n","* `get_diff(old_version, new_version)`\n","  → returns:\n"],"metadata":{"id":"7bcccd36"}},{"id":"da3ace4e","cell_type":"code","metadata":{"id":"da3ace4e"},"execution_count":null,"source":["{\n","  \"summary\": \"... short text ...\",\n","  \"categories\": [...],\n","  \"clusters\": [...],\n","  \"raw_changes\": {...}\n","}"],"outputs":[]},{"id":"1dabd06e","cell_type":"markdown","source":["* `get_change_details(diff_id, cluster_id)`\n","  → returns detailed list of affected objects and raw field changes.\n","\n","* `search_changes(filter)`\n","  Example filter:\n"],"metadata":{"id":"1dabd06e"}},{"id":"0892f5ee","cell_type":"code","metadata":{"id":"0892f5ee"},"execution_count":null,"source":["{\n","  \"story\": \"L14\",\n","  \"object_type\": \"column\",\n","  \"change_type\": \"section_swap\"\n","}"],"outputs":[]},{"id":"7474c854","cell_type":"markdown","source":["With this, a chat-based LLM agent can call tools to fetch diffs and then narrate them back to the user.\n"],"metadata":{"id":"7474c854"}},{"id":"b39fb34a","cell_type":"markdown","source":["# **7. Project spec: roles, phases, deliverables**\n","\n","## 7.1. Roles\n","\n","* ** Engineers / Developers**\n","\n","  * Deep ETABS understanding, can generate test models and validate semantics.\n","  * Implements parsers, diff logic, aggregation, tests.\n","  * Decides thresholds, classification rules, naming conventions (“what counts as a column vs beam”).\n","\n","* **Coding agent (LLM)**\n","\n","  * Assists in:\n","\n","    * Writing & refactoring parsing/diff/aggregation code.\n","    * Writing unit tests.\n","    * Drafting prompts for summarization.\n","    * Generating documentation, CLI, and example notebooks.\n","  * Later, serves as the summarization engine via MCP/API.\n","\n","## 7.2. Phase 0 – Recon & sample collection\n","\n","**Goals:**\n","\n","* Create a small but diverse set of `$et` (and optionally `.e2k`) files:\n","\n","  * Simple 2D frame.\n","  * Multi-story steel frame with grids.\n","  * RC building with walls & slabs.\n","* Create **controlled edits** between versions:\n","\n","  * Change a column size on one story.\n","  * Change all columns on a story.\n","  * Add/delete frames.\n","  * Add/change load combos.\n","* Manually inspect text to identify:\n","\n","  * Section names (`$ FRAME SECTIONS`, `$ JOINT COORDINATES`, `$ LOAD COMBINATIONS`, etc.).\n","  * Field patterns and stable keys.\n","\n","**Deliverable:**\n","Short internal note describing observed patterns, section naming, and mapping from fields to ETABS tables (leveraging CSI docs & Print Tables outputs).\n","\n","## 7.3. Phase 1 – `$et` parser library\n","\n","**Tasks:**\n","\n","* Implement a small **Python library** (e.g. `etabs_text_model`) with:\n","\n","  * `parse_et_file(path: str) -> EtabsModel`\n","  * `serialize_model(model: EtabsModel) -> dict` (JSON-compatible)\n","* Write section-specific parsers:\n","\n","  * For v1: program info, stories, grids, joints, frames, frame sections, load combos, basic assignments.\n","* Unit tests using hand-made fixtures and real `$et` snippets.\n","\n","**Deliverables:**\n","\n","* Library code + docs for the parser.\n","* Test suite demonstrating correct parsing for sample files.\n","\n","## 7.4. Phase 2 – Semantic diff engine\n","\n","**Tasks:**\n","\n","* Implement a module `etabs_model_diff` with:\n","\n","  * `diff_models(old: EtabsModel, new: EtabsModel) -> DiffResult`\n","* Implement:\n","\n","  * Per-collection set-based comparison.\n","  * Field-by-field comparison with tolerance.\n","  * Typed change objects + categories.\n","* Implement aggregation logic to generate clusters:\n","\n","  * Section swap clusters.\n","  * Added/removed object clusters.\n","  * Load combo changes.\n","\n","**Deliverables:**\n","\n","* `DiffResult` JSON schema.\n","* Tests:\n","\n","  * “Single column size change on L14 → one SectionSwapCluster with count=1.”\n","  * “All columns on L14 changed → one cluster with count=N.”\n","  * “New load combo → LoadComboAdded.”\n","\n","## 7.5. Phase 3 – Location tagging (story + grid)\n","\n","**Tasks:**\n","\n","* Parse story and grid definitions; build:\n","\n","  * `story_by_elevation` map.\n","  * `grid_lines_x`, `grid_lines_y` sets with coordinate positions.\n","* For each joint:\n","\n","  * Attach nearest `grid_x`, `grid_y`, `story`.\n","* For each frame:\n","\n","  * Derive a “primary location” from its joints:\n","\n","    * Column: vertical element spanning between stories (same X/Y; Z changes).\n","    * Beam: horizontal element at a story (Z roughly constant).\n","  * Tag object type: column / beam / brace (heuristic based on orientation and assigned section type, optional).\n","\n","**Deliverables:**\n","\n","* Functions to return location descriptors for any frame/joint.\n","* Tests to ensure correct mapping for sample grids.\n","\n","## 7.6. Phase 4 – Summarization API + MCP server\n","\n","**Tasks:**\n","\n","* Define a compact JSON schema for `SummarizationInput` (aggregated clusters).\n","* Write prompts for LLM:\n","\n","  * System prompt: domain context (“You are an ETABS model change explainer…”).\n","  * Example-based instructions (few-shot examples for section swaps, new stories, changed combos).\n","* Implement MCP server:\n","\n","  * Expose `list_model_versions`, `get_diff`, `get_change_details`.\n","  * Use environment-variable configurable paths (project folder with `$et` snapshots).\n","\n","**Deliverables:**\n","\n","* Running MCP server with basic CLI frontend:\n","\n","  * `etabs-log diff v10 v11` → prints Markdown summary.\n","* Sample conversation transcripts showing human designer queries answered via MCP tools.\n","\n","## 7.7. Phase 5 – Integration & UX\n","\n","**Potential integrations:**\n","\n","* **Git hook**:\n","\n","  * Pre-commit or post-commit hook that runs:\n","\n","    * `parse_et_file`, `diff` vs previous commit, then writes a `MODEL_LOG.md` entry.\n","* **VS Code / IDE extension (future)**:\n","\n","  * Panel showing change summaries per commit.\n","* **Internal HTML dashboard**:\n","\n","  * Displays model history, with filters by story, object type, etc.\n"],"metadata":{"id":"b39fb34a"}},{"id":"3b7ff741","cell_type":"markdown","source":["# **8. Non-goals / later ideas**\n","\n","To keep v1 sane:\n","\n","* Do **not** try to cover *all* ETABS tables (foundations, staged construction, pushover hinges, etc.) initially.\n","* Do **not** attempt to reverse-engineer every field from CSI’s internal data dictionary; stick to the tables we actually care about for design review.\n","* Do **not** let the LLM mutate the model (no editing or `.$et` generation in v1) – read-only is safer.\n","\n","Later expansions:\n","\n","* Add coverage for:\n","\n","  * Shell elements (walls, slabs) and their thickness / reinforcement changes.\n","  * Nonlinear hinge properties, spring links.\n","* Use ETABS API directly to supplement text parsing (e.g. to confirm object IDs, geometry, and results).\n"],"metadata":{"id":"3b7ff741"}},{"cell_type":"markdown","source":["# References\n","\n","- https://docs.csiamerica.com/help-files/etabs/Menus/File/Saving_Models.htm\n","- https://www.csiamerica.com/software/ETABS/21/ReleaseNotesETABSv2100.pdf\n","- https://www.eng-tips.com/threads/changing-material-of-line-members.236802/\n","- https://wiki.csiamerica.com/display/kb/Reporting%2BFAQ\n","- https://web.wiki.csiamerica.com/wiki/pages/viewpage.action?pageId=2168039&u\n","- https://www.engineeringskills.com/posts/an-introduction-to-the-etabs-python-api"],"metadata":{"id":"_eDTUnUDOXTc"},"id":"_eDTUnUDOXTc"},{"cell_type":"markdown","source":["\n"],"metadata":{"id":"r_0iO4nFOCmi"},"id":"r_0iO4nFOCmi"},{"cell_type":"code","source":[],"metadata":{"id":"pfKv68PdOR3J"},"id":"pfKv68PdOR3J","execution_count":null,"outputs":[]}]}